#!/usr/bin/env python3
"""
Update performance baseline markdown from benchmark JSON results.

This script converts Google Benchmark JSON output to a human-readable
markdown document for tracking performance over time.
"""

import argparse
import json
import sys
from datetime import datetime
from pathlib import Path
from typing import Any


def load_benchmarks(filepath: str) -> dict[str, Any]:
    """Load benchmark results from JSON file."""
    with open(filepath) as f:
        return json.load(f)


def format_time(value: float, unit: str) -> str:
    """Format time value with appropriate unit."""
    if unit == 'ns':
        if value >= 1_000_000_000:
            return f"{value / 1_000_000_000:.3f}s"
        elif value >= 1_000_000:
            return f"{value / 1_000_000:.3f}ms"
        elif value >= 1_000:
            return f"{value / 1_000:.3f}us"
        return f"{value:.1f}ns"
    return f"{value:.2f}{unit}"


def categorize_benchmarks(data: dict[str, Any]) -> dict[str, list[dict]]:
    """Categorize benchmarks by type."""
    categories = {
        'Container Operations': [],
        'Serialization': [],
        'Value Operations': [],
        'Memory': [],
        'Other': []
    }

    for bench in data.get('benchmarks', []):
        name = bench.get('name', '')

        # Skip aggregate entries
        if any(x in name for x in ['_mean', '_median', '_stddev', '_cv']):
            continue

        # Categorize by name prefix
        if 'Container' in name or 'Create' in name or 'Add' in name:
            categories['Container Operations'].append(bench)
        elif 'Serialize' in name or 'Deserialize' in name:
            categories['Serialization'].append(bench)
        elif 'Value' in name or 'Variant' in name:
            categories['Value Operations'].append(bench)
        elif 'Memory' in name or 'Alloc' in name:
            categories['Memory'].append(bench)
        else:
            categories['Other'].append(bench)

    return categories


def generate_baseline_md(data: dict[str, Any]) -> str:
    """Generate markdown baseline document."""
    lines = []

    # Header
    lines.append("# Performance Baseline\n")
    lines.append(f"**Last Updated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}")
    lines.append(f"**Commit**: {data.get('context', {}).get('git_hash', 'N/A')[:8]}")
    lines.append("")

    # System info
    context = data.get('context', {})
    lines.append("## System Information\n")
    lines.append(f"- **Host**: {context.get('host_name', 'N/A')}")
    lines.append(f"- **CPUs**: {context.get('num_cpus', 'N/A')}")
    lines.append(f"- **CPU MHz**: {context.get('mhz_per_cpu', 'N/A')}")
    lines.append(f"- **Build Type**: Release")
    lines.append("")

    # Categorized results
    categories = categorize_benchmarks(data)

    for category, benchmarks in categories.items():
        if not benchmarks:
            continue

        lines.append(f"## {category}\n")
        lines.append("| Benchmark | Time | CPU | Iterations |")
        lines.append("|-----------|------|-----|------------|")

        for bench in sorted(benchmarks, key=lambda x: x.get('name', '')):
            name = bench.get('name', 'Unknown')
            time_unit = bench.get('time_unit', 'ns')
            real_time = bench.get('real_time', 0)
            cpu_time = bench.get('cpu_time', 0)
            iterations = bench.get('iterations', 0)

            real_str = format_time(real_time, time_unit)
            cpu_str = format_time(cpu_time, time_unit)

            lines.append(f"| `{name}` | {real_str} | {cpu_str} | {iterations:,} |")

        lines.append("")

    # Summary statistics
    all_benchmarks = data.get('benchmarks', [])
    valid_benchmarks = [
        b for b in all_benchmarks
        if not any(x in b.get('name', '') for x in ['_mean', '_median', '_stddev', '_cv'])
    ]

    lines.append("## Summary\n")
    lines.append(f"- **Total Benchmarks**: {len(valid_benchmarks)}")

    if valid_benchmarks:
        times = [b.get('real_time', 0) for b in valid_benchmarks]
        lines.append(f"- **Fastest**: {format_time(min(times), 'ns')}")
        lines.append(f"- **Slowest**: {format_time(max(times), 'ns')}")

    lines.append("")
    lines.append("---")
    lines.append("*This baseline is automatically generated by CI.*")

    return "\n".join(lines)


def main():
    parser = argparse.ArgumentParser(
        description='Generate baseline markdown from benchmark JSON'
    )
    parser.add_argument(
        'input',
        help='Input benchmark JSON file'
    )
    parser.add_argument(
        'output',
        help='Output markdown file'
    )

    args = parser.parse_args()

    # Validate input
    if not Path(args.input).exists():
        print(f"Error: Input file not found: {args.input}")
        sys.exit(1)

    # Load and convert
    data = load_benchmarks(args.input)
    markdown = generate_baseline_md(data)

    # Ensure output directory exists
    Path(args.output).parent.mkdir(parents=True, exist_ok=True)

    # Write output
    with open(args.output, 'w') as f:
        f.write(markdown)

    print(f"Baseline updated: {args.output}")

    # Print summary
    benchmarks = data.get('benchmarks', [])
    valid = [b for b in benchmarks if '_mean' not in b.get('name', '')]
    print(f"  - Benchmarks: {len(valid)}")


if __name__ == '__main__':
    main()
